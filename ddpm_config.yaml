DDPM:
  n_samples: 1000000
  sigma: 0.1
  beta_start: 0.0001 # 初期時刻のβ_0
  beta_end: 0.02 # 終端時刻のβ_T
  n_steps: 1000 # 拡散過程の分割ステップ数

sampling:  # DDPMサンプリング
  n_samples: 100000  # DDPMサンプリングを動かすときのサンプル数
  alpha: 0.1
  n_steps: 200

model:
  n_channels: 2
  n_hidden: 2
  h_dim: 32
  loss_weight: 1.0

training:
  batch_size: 512  # バッチサイズ
  n_steps: 100000  # スコアモデルの訓練ステップ数
  log_step: 1000  # lossを何stepおきにレポートするか
  optim:
    optimizer:  # 最適化アルゴリズム
      name: Adam
      params:  # 最適化アルゴリズムに応じて項目を追加したり減らしたりする
        lr: 0.0001  # 学習率
        betas: [0.9, 0.999]
        eps: 1e-08
        weight_decay: 0
    lr_scheduler:  # 学習率調整アルゴリズム
      name: OneCycleLR
      params:
        max_lr: 0.001
        total_steps: 100000
  use_scheduler: True  # 学習率スケジューリングを使うか否か
